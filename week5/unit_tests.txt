Setting the ball rolling for test cases for Exercise 4

Assignment #1 [Feedforward and Cost Function]
[J] = nnCostFunction(sec(1:1:32)', 2, 4, 4, reshape(tan(1:32), 16, 2) / 5, 1 + mod(1:16,4)', 0);

J =  10.93

Assignment #2 [Regularized Cost Function]
[J] = nnCostFunction(sec(1:1:32)', 2, 4, 4, reshape(tan(1:32), 16, 2) / 5, 1 + mod(1:16,4)', 0.1);
J =  170.99

Assignment #3 [Sigmoid Gradient]
[sigGrad] = sigmoidGradient(sec(1:1:5)')
sigGrad =

   0.117342
   0.076065
   0.195692
   0.146323
   0.027782

Assignment #4 [Neural Network Gradient (Backpropagation)] [provided by Sindhuja V]
[J grad] = nnCostFunction(sec(1:1:32)', 2, 4, 4, reshape(tan(1:32), 16, 2) / 5, 1 + mod(1:16,4)', 0);

J =  10.931
grad =
  3.0518e-001
  7.1044e-002
  5.1307e-002
  6.2115e-001
  -7.4310e-002
  5.2173e-002
  -2.9711e-003
  -5.5435e-002
  -9.5647e-003
  -4.6995e-002
  1.0499e-004
  9.0452e-003
  -7.4506e-002
  7.4997e-001
  -1.7991e-002
  4.4328e-001
  -5.9840e-002
  5.3455e-001
  -7.8995e-002
  3.5278e-001
  -5.3284e-003
  8.4440e-002
  -3.4384e-002
  6.6441e-002
  -3.4314e-002
  3.3322e-001
  -7.0455e-002
  1.5063e-001
  -1.7708e-002
  2.7170e-001
  7.1129e-002
  1.4488e-001

Assignment #5 [Regularized Gradient]
[J grad] = nnCostFunction(sec(1:1:32)', 2, 4, 4, reshape(tan(1:32), 16, 2) / 5, 1 + mod(1:16,4)', 0.1);
J =  170.99
grad =

   0.3051843
   0.0710438
   0.0513066
   0.6211486
  -0.0522766
   0.0586827
   0.0053191
  -0.0983900
  -0.0164243
  -0.0544438
   1.4123116
   0.0164517
  -0.0745060
   0.7499671
  -0.0179905
   0.4432801
  -0.0825542
   0.5440175
  -0.0726739
   0.3680935
  -0.0167392
   0.0781902
  -0.0461142
   0.0811755
  -0.0280090
   0.3428785
  -0.0918487
   0.1441408
  -0.0260627
   0.3122174
   0.0779614
   0.1523740